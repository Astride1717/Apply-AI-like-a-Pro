{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNUO0EpXWff3MohMSJkdMt1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atktQdrQ9z5x","executionInfo":{"status":"ok","timestamp":1693703417075,"user_tz":300,"elapsed":490,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}},"outputId":"ffca359f-3143-41f1-bbf5-d044ab782851"},"outputs":[{"output_type":"stream","name":"stdout","text":["               total        used        free      shared  buff/cache   available\n","Mem:            83Gi       857Mi        80Gi       1.0Mi       2.3Gi        81Gi\n","Swap:             0B          0B          0B\n"]}],"source":["!free -h"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSi6wUaN-VuP","executionInfo":{"status":"ok","timestamp":1693703436470,"user_tz":300,"elapsed":373,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}},"outputId":"1a59ced8-a263-452e-ab15-bdf66dcd6dab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  3 01:10:36 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["pip install deepspeed>=0.9.0\n"],"metadata":{"id":"ucohP5Se-NRW","executionInfo":{"status":"ok","timestamp":1693703475563,"user_tz":300,"elapsed":18604,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FO1rYED_hNs","executionInfo":{"status":"ok","timestamp":1693703489605,"user_tz":300,"elapsed":11092,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}},"outputId":"268bfaaf-b91f-4757-9fee-db1c4bceea6e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"]}]},{"cell_type":"code","source":["from torch import nn\n","from transformers import Trainer\n","\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        # compute custom loss (suppose one has 3 labels with different weights)\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0], device=model.device))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"],"metadata":{"id":"66rC8PPr_run","executionInfo":{"status":"ok","timestamp":1693703514881,"user_tz":300,"elapsed":5729,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HsgozWM_4D8","executionInfo":{"status":"ok","timestamp":1693703718522,"user_tz":300,"elapsed":4648,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}},"outputId":"c62f3296-3b4e-4b4a-e0e4-9dadc4acbe18"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Requirement already satisfied: torch==1.11.0+cu113 in /usr/local/lib/python3.10/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: torchvision==0.12.0+cu113 in /usr/local/lib/python3.10/dist-packages (0.12.0+cu113)\n","Requirement already satisfied: torchaudio==0.11.0+cu113 in /usr/local/lib/python3.10/dist-packages (0.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2023.7.22)\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/microsoft/deepspeed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QY0b4Zb9A4Ft","executionInfo":{"status":"ok","timestamp":1693703750557,"user_tz":300,"elapsed":24682,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}},"outputId":"15203057-e562-470a-8d40-486498bffe18"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/microsoft/deepspeed\n","  Cloning https://github.com/microsoft/deepspeed to /tmp/pip-req-build-6p1xxqfh\n","  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/deepspeed /tmp/pip-req-build-6p1xxqfh\n","  Resolved https://github.com/microsoft/deepspeed to commit a23cda6c3bb27b141b13ba231a53190507bf35ae\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (3.1.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (1.11.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (9.0.0)\n","Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (1.10.12)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (1.11.0+cu113)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.10.3+a23cda6c) (4.66.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed==0.10.3+a23cda6c) (4.7.1)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.10.3+a23cda6c-py3-none-any.whl size=898759 sha256=b2a481c1f81b6b34d1426f388029f2d5493ff5ec4ff2e3551ce0b14798e48634\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-dgvr3e9y/wheels/c7/2a/60/6cd1be5e9093337b6243efab085ade35b787b5c4c1aaf99387\n","Successfully built deepspeed\n","Installing collected packages: deepspeed\n","  Attempting uninstall: deepspeed\n","    Found existing installation: deepspeed 0.10.2\n","    Uninstalling deepspeed-0.10.2:\n","      Successfully uninstalled deepspeed-0.10.2\n","Successfully installed deepspeed-0.10.3+a23cda6c\n"]}]},{"cell_type":"code","source":["%%bash\n","git clone https://github.com/huggingface/transformers\n","cd transformers\n","# examples change a lot so let's pick a sha that we know this notebook will work with\n","# comment out/remove the next line if you want the master\n","git checkout 0aac9ba2dabcf9\n","pip install -e .\n","pip install -r examples/pytorch/translation/requirements.txt\n","\n","# if needed free up some space used by cached pip packages\n","# rm -rf /root/.cache/pip"],"metadata":{"id":"PgO9Mb-tBX7E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cd transformers\n","\n","cat <<'EOT' > ds_config.json\n","{\n","    \"fp16\": {\n","        \"enabled\": \"auto\",\n","        \"loss_scale\": 0,\n","        \"loss_scale_window\": 1000,\n","        \"initial_scale_power\": 16,\n","        \"hysteresis\": 2,\n","        \"min_loss_scale\": 1\n","    },\n","\n","    \"optimizer\": {\n","        \"type\": \"AdamW\",\n","        \"params\": {\n","            \"lr\": \"auto\",\n","            \"betas\": \"auto\",\n","            \"eps\": \"auto\",\n","            \"weight_decay\": \"auto\"\n","        }\n","    },\n","\n","    \"scheduler\": {\n","        \"type\": \"WarmupLR\",\n","        \"params\": {\n","            \"warmup_min_lr\": \"auto\",\n","            \"warmup_max_lr\": \"auto\",\n","            \"warmup_num_steps\": \"auto\"\n","        }\n","    },\n","\n","    \"zero_optimization\": {\n","        \"stage\": 2,\n","        \"offload_optimizer\": {\n","            \"device\": \"cpu\",\n","            \"pin_memory\": true\n","        },\n","        \"allgather_partitions\": true,\n","        \"allgather_bucket_size\": 2e8,\n","        \"overlap_comm\": true,\n","        \"reduce_scatter\": true,\n","        \"reduce_bucket_size\": 2e8,\n","        \"contiguous_gradients\": true\n","    },\n","\n","    \"gradient_accumulation_steps\": \"auto\",\n","    \"gradient_clipping\": \"auto\",\n","    \"steps_per_print\": 2000,\n","    \"train_batch_size\": \"auto\",\n","    \"train_micro_batch_size_per_gpu\": \"auto\",\n","    \"wall_clock_breakdown\": false\n","}\n","EOT"],"metadata":{"id":"FfoifUA99rDM","executionInfo":{"status":"ok","timestamp":1693703863123,"user_tz":300,"elapsed":525,"user":{"displayName":"Vito Trase","userId":"06733091175621095357"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!cd transformers; export BS=16; rm -rf output_dir; \\\n","PYTHONPATH=src USE_TF=0 CUDA_VISIBLE_DEVICES=0 deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \\\n","--model_name_or_path t5-small --output_dir output_dir --adam_eps 1e-06 --evaluation_strategy=steps \\\n","--do_train --do_eval --label_smoothing 0.1 --learning_rate 3e-5 --logging_first_step --logging_steps 1000 \\\n","--max_source_length 128 --max_target_length 128 --num_train_epochs 1 --overwrite_output_dir  \\\n","--per_device_train_batch_size $BS --per_device_eval_batch_size $BS --predict_with_generate --sortish_sampler \\\n","--val_max_target_length 128 --warmup_steps 500 --max_train_samples 2000 --max_eval_samples 500 \\\n","--dataset_name wmt16 --dataset_config ro-en --source_lang en --target_lang ro \\\n","#--source_prefix \"translate English to Romanian: \" --deepspeed ds_config.json --fp16"],"metadata":{"id":"4gnKNxGp9xAD"},"execution_count":null,"outputs":[]}]}